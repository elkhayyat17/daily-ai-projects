# ğŸª¶ Day 07 â€” Light RAG: Lightweight Retrieval-Augmented Generation

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-teal?logo=fastapi)
![NumPy](https://img.shields.io/badge/NumPy-Vector_Search-orange?logo=numpy)
![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)

> **Zero-dependency vector database** â€” hybrid BM25 + cosine search powered by NumPy and `rank-bm25`. No LangChain. No ChromaDB. No FAISS. Just pure, lightweight RAG.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Light RAG Pipeline                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ğŸ“¥ Documents â”€â”€â–º Chunking â”€â”€â–º Embedding â”€â”€â–º NumPy Matrix    â”‚
â”‚                                    â”‚              â”‚           â”‚
â”‚                              BM25 Index     Dense Index       â”‚
â”‚                                    â”‚              â”‚           â”‚
â”‚  ğŸ” Query â”€â”€â”€â”€â”€â–º Preprocessing â”€â”€â”€â–ºâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚                                    â”‚              â”‚           â”‚
â”‚                               BM25 Scores   Cosine Scores    â”‚
â”‚                                    â”‚              â”‚           â”‚
â”‚                                    â–¼              â–¼           â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                              â”‚   Weighted Fusion    â”‚         â”‚
â”‚                              â”‚  (0.3 BM25 + 0.7    â”‚         â”‚
â”‚                              â”‚   Semantic)          â”‚         â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                       â”‚                       â”‚
â”‚                                  Top-K Chunks                 â”‚
â”‚                                       â”‚                       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                              â”‚  Answer Generation   â”‚         â”‚
â”‚                              â”‚  (OpenAI or Extract) â”‚         â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Differentiators

| Feature | Day 03 (Heavy RAG) | **Day 07 (Light RAG)** |
|---------|--------------------|-----------------------|
| Embeddings | LangChain wrapper | Direct `sentence-transformers` |
| Vector Store | ChromaDB server | **NumPy `.npy` file** |
| Keyword Search | âŒ None | **BM25Okapi** |
| Retrieval | Semantic only | **Hybrid (BM25 + Cosine)** |
| Dependencies | LangChain, ChromaDB, etc. | **NumPy, rank-bm25** |
| Index Size | ~100 MB+ | **< 5 MB** |
| Startup Time | Seconds | **Milliseconds** |

---

## ğŸš€ Quick Start

### 1. Install

```bash
cd day_07_light_rag
pip install -r requirements.txt
```

### 2. Prepare Data & Build Index

```bash
python -m data.prepare_data
python -m training.train
```

### 3. Evaluate

```bash
python -m training.evaluate
```

### 4. Start API

```bash
uvicorn api.main:app --reload
```

### 5. Launch Demo UI

```bash
streamlit run app/streamlit_app.py
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check + index status |
| `POST` | `/query` | Ask a question (hybrid/semantic/bm25) |
| `POST` | `/ingest` | Add documents to the live index |
| `GET` | `/stats` | Index statistics |

### Example: Query

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is hybrid search?", "mode": "hybrid", "top_k": 5}'
```

### Example: Ingest

```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{"items": [{"id": "new-1", "title": "My Doc", "content": "New content..."}]}'
```

---

## ğŸ³ Docker

```bash
cd docker
docker compose up --build
```

---

## ğŸ§ª Tests

```bash
cd day_07_light_rag
pytest tests/ -v
```

**30+ tests** covering:
- Query preprocessing & validation
- Text chunking strategies
- Data pipeline
- Embedding models
- Index save/load roundtrip
- Predictor (all 3 modes)
- Ingestion
- API endpoints (health, query, ingest, stats)
- Evaluation metrics

---

## ğŸ“ Project Structure

```
day_07_light_rag/
â”œâ”€â”€ config.py                    # Centralized settings
â”œâ”€â”€ requirements.txt             # Minimal dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”œâ”€â”€ routes.py                # API endpoints
â”‚   â””â”€â”€ schemas.py               # Pydantic models
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py         # Interactive demo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prepare_data.py          # Document chunking pipeline
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ model.py                 # Embedding factory (local/OpenAI/fake)
â”‚   â”œâ”€â”€ train.py                 # Build hybrid index (NumPy + BM25)
â”‚   â””â”€â”€ evaluate.py              # Hit-rate & MRR evaluation
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ predictor.py             # Light RAG predictor (singleton)
â”‚   â””â”€â”€ preprocessing.py         # Query validation
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile               # Multi-stage build
â”‚   â””â”€â”€ docker-compose.yml       # Service orchestration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_predictor.py        # Unit tests (20+)
â”‚   â””â”€â”€ test_api.py              # Integration tests (15+)
â””â”€â”€ notebooks/
    â””â”€â”€ exploration.ipynb        # Data exploration
```

---

## âš™ï¸ Configuration

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `EMBEDDING_PROVIDER` | `local` | `local`, `openai`, or `fake` |
| `LOCAL_EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | Sentence-transformers model |
| `OPENAI_API_KEY` | â€” | Enables OpenAI embeddings + generation |
| `LIGHTRAG_TOP_K` | `5` | Default retrieval depth |
| `LIGHTRAG_CHUNK_SIZE` | `512` | Characters per chunk |
| `LIGHTRAG_BM25_WEIGHT` | `0.3` | BM25 score weight in hybrid mode |
| `LIGHTRAG_SEMANTIC_WEIGHT` | `0.7` | Semantic score weight in hybrid mode |

---

## ğŸ“Š Retrieval Modes

- **`hybrid`** (default) â€” Weighted fusion of BM25 + cosine similarity
- **`semantic`** â€” Pure dense vector search (cosine similarity)
- **`bm25`** â€” Pure keyword search (BM25Okapi)

---

Built with â¤ï¸ as part of the [Daily AI Projects](https://github.com/elkhayyat17/daily-ai-projects) challenge.
